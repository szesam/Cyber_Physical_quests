# Quest Name
Authors: Carmen Hurtado , Samuel Sze, Hazim Halim

Date: 2021-04-29
-----

## Summary
**Contributors:**
Samuel | Carmen | Hazim

In this quest we designed a semi-autonomous crawler which has the ability for cruise control using a PID controller as well as being controlled by a user through buttons on a web page. Our crawler has a variety of sensors and devices attached to achieve a more accurate manuver. We have attached the following onto the crawler: 
    1) LIDAR Lite V3 facing front.
    2) Optical Encoder in the back right wheel. 
    3) Accelerometer on the top. 
    4) IR Range Finder facing the right side.
    5) RaspberryPi Camera facing the front. 
    6) Alphanumeric Display on the left side.
Once turned on the user must start the Buggy by pressing the START button. From here the autonomous part and the manual part can begin to take place. The crawler is programmed maintain a speed of 2 cm/sec using PID controller and the speed calculated using the Optical Encoder. We have also included an IR range sensor that aids in keeping the crawler's center course by steering it to the center when it goes lower than our setpoint of 50 cm. Our system also features obstacle avoidance with the front facing LIDAR sensor. If the LIDAR detects an obstacle within 1 meter or less, it will send a warning message to the webpage from where the user can avoid a collision through visual aid from the Raspberry Pi Camera. If any obstacle comes within 20 cm of the crawler, it will automatically stop as an emergency collision resposne.
All communications between the Crawler and the user is done via a UDP protocol and Wifi connection. 

## Self-Assessment

### Objective Criteria

| Objective Criterion | Rating | Max Value  | 
|---------------------------------------------|:-----------:|:---------:|
| Objective One | 1 |  1     | 
| Objective Two | 1 |  1     | 
| Objective Three | 1 |  1     | 
| Objective Four | 1 |  1     | 
| Objective Five |  1|  1     | 
| Objective Six | 1 |  1     | 
| Objective Seven | 1 |  1     | 


### Qualitative Criteria

| Qualitative Criterion | Rating | Max Value  | 
|---------------------------------------------|:-----------:|:---------:|
| Quality of solution | 5 |  5     | 
| Quality of report.md including use of graphics | 3 |  3     | 
| Quality of code reporting | 3 |  3     | 
| Quality of video presentation | 3 |  3     | 


## Solution Design
<<<<<<< HEAD
=======
### Front End and UDP Protocol Communication:
For this quest we are asked to set up a web page through a web server in which a user can control the motion of the crawler. Not only do the user get to start, stop, and steer the crawler, but the page also displays data back to the user. This data includes distance traveled, calculated using an Optical Encoder. It also includes crawler speed calculated using two different devices, the previoulsy mentioned optical encoder and an ADXL343 accelerometer.
We have set up the communication between the ESP32 and the server using UDP protocol through a Wifi generated by the Loaned Router. Using UDP we send a payload that includes the sensor data and it is transmitted every one second. At the server side, we receive this message and we transfer the separated data to the web page using SocketIO. This transmission happens every one second, and therefore information in the web page is updated every one second. 
The web page features 4 buttons. START BUGGY, STOP BUGGY, STEER RIGHT, STEER LEFT. Once one of these buttons is pressed, a message is sent back to the udp client(ESP32) and the Crawler acts accordingly. 
>>>>>>> f7c102bcb7e958e945ec88f55cb74ed3f2d60839

### Front End and UDP Protocol Communication:

For this quest we are asked to set up a web page through a web server in which a user can control the motion of the crawler. Not only do the user get to start, stop, and steer the crawler, but the page also displays data back to the user. This data includes distance traveled, calculated using an Optical Encoder. It also includes crawler speed calculated using two different devices, the previoulsy mentioned optical encoder and an ADXL343 accelerometer.

We have set up the communication between the ESP32 and the server using UDP protocol through a Wifi generated by the Loaned Router. Using UDP we send a payload that includes the sensor data and it is transmitted every one second. At the server side, we receive this message and we transfer the separated data to the web page using SocketIO. This transmission happens every one second, and therefore information in the web page is updated every one second. 

The web page features 4 buttons. START BUGGY, STOP BUGGY, STEER RIGHT, STEER LEFT. Once one of these buttons is pressed, a message is sent back to the udp client(ESP32) and the Crawler acts accordingly. 

### Velocity from ADXL343

Other than the encoder, we also used the accelerometer to detect the current speed of the crawler.
Since the ADXL343 only detects the acceleration, we had to use "v = u + aT" to figure out the velocity (where u = initial velocity, a = sampled acceleration, T = sampling period).  The acceleration taken is only the acceleration on the x-axis
However, since we can't do an integration on the accelerometer, this is only an aproximation. The approximate results are close the value measured by the encoder but there are still inaccuracies.

The results are then send to the web page to be displayed alongside the speed measured by the encoder.

### Steering

Steering the crawler involves controlling the servo.
The angle values to steer the crawler in straight, left, and right are 90, 0, and 180 degrees respectively.

The fucntionality of the steering is used the following cases:
    1) Steer left or Steer right button is pushed on the webpage
    2) The IR detects objects too close (< 50cm) to the crawler and needs to steer clear of the obstacle.
    
### LIDAR, IR distance sensors

One LIDAR (GARMIN) v3 is attached to the front of the buggy, which provides distance sensing in the forward direction for any obstacles up to 40 meters. It uses I2C as the communication channel. The distance reported by this LIDAR will be used in the Crawler's driving servo ESC to stop the movement of the Crawler when an obstacle is within 30cm. In addition, distance is also reported through UDP into the webpage and displayed to let the user know if there is an obstacle in front. This facilitates the steering and stopping option on the buggy as well. 

The IR sensor is positioned on the side of the buggy, which is used for side sensing and maintaining the buggy's course through adjusting the steering servo. It uses an ADC channel. When the IR sensor detects an obstacle/wall that is within 50cm of itself, it will tell the steering servo to steer in the opposite direction. 

### Wheel encoder Speed

The QRD1114 encoder is the primary sensor used to calculate the speed of the buggy and estimate its distance travelled. The wheel encoder through an ADC channel and uses an LED to detect a difference in adc reading. When the LED hits a black surface, all signal is reflected, and thus the adc_reading is at maximum. When the LED hits a white surface, all signal is absorbed, and thus the adc_reading is at a minimum. By attaching a wheel encoder template on one of the side wheels, the encoder is able to calculate the change in colors as the wheel spins. This can then be converted to the wheel speed and distance travelled. 

### PID 

The PID control is used maintain the buggy's speed within a setpoint. The proportional control dictates most of the error control, while derivate and integral contributes about 1/10th of the adjustment. The setpoint is set at 1.5m/s, with the driving servo incrementing at 10steps of MCPWM pulse width to reach that setpoint. 

### Crawler Build and Circuitry:

Additional devices used:

1. Alphanumeric 14-seg display. 

2. Raspberry Pi and Camera.

Put photo here.
    
### Obstacle Avoidance

To solve the issue of obstacle avoidance, we used the RPi camera to give the user a view of the crawler's path.
Anytime the LIDAR detects an object that is within 1 meter of it, a warning message is sent to the webpage via a UDP socket. The warning basically tells the user that there might be a collision if the path is the same. The user then, with the visual feedback from the RPi camera, can choose to steer right or left by clicking the button aptly named "Steer Right" and "Steer Left" on the webpage.

If the user doesn't take action and the object is now within 30cm of the crawler, it will automatically stop and send another warning to the user. The crawler will remain still until the user chooses to steer clear of the obstacle.


## Sketches and Photos
<center><img src="./images/ece444.png" width="25%" /></center>  
<center> </center>


## Supporting Artifacts
- [Link to video demo](). Not to exceed 120s


## Modules, Tools, Source Used Including Attribution
- ESP32
- Lidar Lite V3
- IR range finder 
- ADC
- I2C
- Optical Encoder 
- ADXL343
- RaspberryPi Camera
- Alphanumeric Display
- UDP 
- Node Js
- SocketIO
## References

-----

